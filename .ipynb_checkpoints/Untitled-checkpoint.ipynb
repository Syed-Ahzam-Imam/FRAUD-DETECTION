{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bc5194f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import scipy as scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9f6c3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bene_df = pd.read_csv(\"Dataset/Train_Beneficiarydata-1542865627584.csv\")\n",
    "train_ip_df = pd.read_csv(\"Dataset/Train_Inpatientdata-1542865627584.csv\")\n",
    "train_op_df = pd.read_csv(\"Dataset/Train_Outpatientdata-1542865627584.csv\")\n",
    "train_tgt_lbls_df = pd.read_csv(\"Dataset/Train-1542865627584.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "09d41734",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ip_df[\"Admitted?\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "830497e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op_df[\"Admitted?\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c994590b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Commom columns must be 28\n",
    "common_cols = [col for col in train_ip_df.columns if col in train_op_df.columns]\n",
    "len(common_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "44e1eae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(558211, 31)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging the IP and OP dataset on the basis of common columns\n",
    "train_ip_op_df = pd.merge(left=train_ip_df, right=train_op_df, left_on=common_cols, right_on=common_cols, how=\"outer\")\n",
    "train_ip_op_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c67212f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(558211, 55)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining the IP_OP dataset with the BENE data\n",
    "train_ip_op_bene_df = pd.merge(left=train_ip_op_df, right=train_bene_df, left_on='BeneID', right_on='BeneID',how='inner')\n",
    "train_ip_op_bene_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "31446134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(558211, 56)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining the IP_OP_BENE dataset with the Tgt Label Provider Data\n",
    "train_iobp_df = pd.merge(left=train_ip_op_bene_df, right=train_tgt_lbls_df, left_on='Provider', right_on='Provider',how='inner')\n",
    "train_iobp_df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f352c02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df = train_iobp_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "552c9618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>ClaimID</th>\n",
       "      <th>PotentialFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRV55912</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Provider  ClaimID PotentialFraud\n",
       "0  PRV55912        1            Yes"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining with the PRV Tgt Labels\n",
    "prvs_claims_df = pd.DataFrame(train_iobp_df.groupby(['Provider'])['ClaimID'].count()).reset_index()\n",
    "prvs_claims_tgt_lbls_df = pd.merge(left=prvs_claims_df, right=train_tgt_lbls_df, on='Provider', how='inner')\n",
    "prvs_claims_tgt_lbls_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "49358310",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df['DOB'] = pd.to_datetime(train_iobp_df['DOB'], format=\"%Y-%m-%d\")\n",
    "train_iobp_df['DOD'] = pd.to_datetime(train_iobp_df['DOD'], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "355b0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df['Is_Alive?'] = train_iobp_df['DOD'].apply(lambda val: 'No' if val != val else 'Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3d119338",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df['ClaimStartDt'] = pd.to_datetime(train_iobp_df['ClaimStartDt'], format=\"%Y-%m-%d\")\n",
    "train_iobp_df['ClaimEndDt'] = pd.to_datetime(train_iobp_df['ClaimEndDt'], format=\"%Y-%m-%d\")\n",
    "\n",
    "train_iobp_df['Claim_Duration'] = (train_iobp_df['ClaimEndDt'] - train_iobp_df['ClaimStartDt']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9c651d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df['AdmissionDt'] = pd.to_datetime(train_iobp_df['AdmissionDt'], format=\"%Y-%m-%d\")\n",
    "train_iobp_df['DischargeDt'] = pd.to_datetime(train_iobp_df['DischargeDt'], format=\"%Y-%m-%d\")\n",
    "\n",
    "train_iobp_df['Admitted_Duration'] = (train_iobp_df['DischargeDt'] - train_iobp_df['AdmissionDt']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "dff84905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the Null values as MAX Date of Death in the Dataset\n",
    "train_iobp_df['DOD'].fillna(value=train_iobp_df['DOD'].max(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e5c2d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df['Bene_Age'] = round(((train_iobp_df['DOD'] - train_iobp_df['DOB']).dt.days)/365,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6c9c116b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.0\n",
       "mean     1.0\n",
       "std      NaN\n",
       "min      1.0\n",
       "25%      1.0\n",
       "50%      1.0\n",
       "75%      1.0\n",
       "max      1.0\n",
       "Name: Att_Phy_tot_claims, dtype: float64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iobp_df['Att_Phy_tot_claims'] = train_iobp_df.groupby(['AttendingPhysician'])['ClaimID'].transform('count')\n",
    "train_iobp_df['Att_Phy_tot_claims'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "634d98d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    0.0\n",
       "mean     NaN\n",
       "std      NaN\n",
       "min      NaN\n",
       "25%      NaN\n",
       "50%      NaN\n",
       "75%      NaN\n",
       "max      NaN\n",
       "Name: Opr_Phy_tot_claims, dtype: float64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iobp_df['Opr_Phy_tot_claims'] = train_iobp_df.groupby(['OperatingPhysician'])['ClaimID'].transform('count')\n",
    "train_iobp_df['Opr_Phy_tot_claims'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4cc22e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    0.0\n",
       "mean     NaN\n",
       "std      NaN\n",
       "min      NaN\n",
       "25%      NaN\n",
       "50%      NaN\n",
       "75%      NaN\n",
       "max      NaN\n",
       "Name: Oth_Phy_tot_claims, dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iobp_df['Oth_Phy_tot_claims'] = train_iobp_df.groupby(['OtherPhysician'])['ClaimID'].transform('count')\n",
    "train_iobp_df['Oth_Phy_tot_claims'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "57df9027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the combined feature\n",
    "train_iobp_df['Att_Phy_tot_claims'].fillna(value=0, inplace=True)\n",
    "train_iobp_df['Opr_Phy_tot_claims'].fillna(value=0, inplace=True)\n",
    "train_iobp_df['Oth_Phy_tot_claims'].fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "dd56b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df['Att_Opr_Oth_Phy_Tot_Claims'] = train_iobp_df['Att_Phy_tot_claims'] + train_iobp_df['Opr_Phy_tot_claims'] + train_iobp_df['Oth_Phy_tot_claims']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ef12e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df.drop(['Att_Phy_tot_claims', 'Opr_Phy_tot_claims', 'Oth_Phy_tot_claims'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bdd4d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df[\"Prv_Tot_Att_Phy\"] = train_iobp_df.groupby(['Provider'])['AttendingPhysician'].transform('count')\n",
    "train_iobp_df[\"Prv_Tot_Opr_Phy\"] = train_iobp_df.groupby(['Provider'])['OperatingPhysician'].transform('count')\n",
    "train_iobp_df[\"Prv_Tot_Oth_Phy\"] = train_iobp_df.groupby(['Provider'])['OtherPhysician'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "987655c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df['Prv_Tot_Att_Opr_Oth_Phys'] = train_iobp_df['Prv_Tot_Att_Phy'] + train_iobp_df['Prv_Tot_Opr_Phy'] + train_iobp_df['Prv_Tot_Oth_Phy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "115d0481",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df.drop(['Prv_Tot_Att_Phy', 'Prv_Tot_Opr_Phy', 'Prv_Tot_Oth_Phy'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "99ea2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df['PRV_Tot_Admit_DCodes'] = train_iobp_df.groupby(['Provider'])['ClmAdmitDiagnosisCode'].transform('nunique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9312da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df['PRV_Tot_DGrpCodes'] = train_iobp_df.groupby(['Provider'])['DiagnosisGroupCode'].transform('nunique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f6cff414",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df['DOB_Year'] = train_iobp_df['DOB'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "66a95bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df['PRV_Tot_Unq_DOB_Years'] = train_iobp_df.groupby(['Provider'])['DOB_Year'].transform('nunique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "82345666",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df.drop(['DOB_Year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "40aabc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df['PRV_Bene_Age_Sum'] = train_iobp_df.groupby(['Provider'])['Bene_Age'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d1cd062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df['PRV_Insc_Clm_ReImb_Amt'] = train_iobp_df.groupby(['Provider'])['InscClaimAmtReimbursed'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "40faa82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df['RenalDiseaseIndicator'] = train_iobp_df['RenalDiseaseIndicator'].apply(lambda val: 1 if val == \"Y\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "28d3b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iobp_df['PRV_Tot_RKD_Patients'] = train_iobp_df.groupby(['Provider'])['RenalDiseaseIndicator'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b5c8e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping these 2 columns as there 99% of values are same\n",
    "train_iobp_df.drop(['NoOfMonths_PartACov', 'NoOfMonths_PartBCov'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fb7a5b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling null values in Admitted_Duration with 0 (as it will represent the patients were admitted for 0 days)\n",
    "train_iobp_df['Admitted_Duration'].fillna(value=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6a82b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRV Aggregate features\n",
    "train_iobp_df[\"PRV_CoPayment\"] = train_iobp_df.groupby('Provider')['DeductibleAmtPaid'].transform('sum')\n",
    "train_iobp_df[\"PRV_IP_Annual_ReImb_Amt\"] = train_iobp_df.groupby('Provider')['IPAnnualReimbursementAmt'].transform('sum')\n",
    "train_iobp_df[\"PRV_IP_Annual_Ded_Amt\"] = train_iobp_df.groupby('Provider')['IPAnnualDeductibleAmt'].transform('sum')\n",
    "train_iobp_df[\"PRV_OP_Annual_ReImb_Amt\"] = train_iobp_df.groupby('Provider')['OPAnnualReimbursementAmt'].transform('sum')\n",
    "train_iobp_df[\"PRV_OP_Annual_Ded_Amt\"] = train_iobp_df.groupby('Provider')['OPAnnualDeductibleAmt'].transform('sum')\n",
    "train_iobp_df[\"PRV_Admit_Duration\"] = train_iobp_df.groupby('Provider')['Admitted_Duration'].transform('sum')\n",
    "train_iobp_df[\"PRV_Claim_Duration\"] = train_iobp_df.groupby('Provider')['Claim_Duration'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c162860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agg_feats(grp_col, feat_name, operation='sum'):\n",
    "    \"\"\"\n",
    "    Description :: This function is created for adding the aggregated features in the dataset for every level like:\n",
    "        - Beneficiary\n",
    "        - Attending Physician\n",
    "        - Operating Physician\n",
    "        - Other Physician and etc..\n",
    "        \n",
    "    Input Parameters :: It accepts below inputs:\n",
    "        - grp_col : `str`\n",
    "            - It represents the feature or level at which you want to perform the aggregation.\n",
    "        \n",
    "        - feat_name : `str`\n",
    "            - It represents the feature whose aggregated aspect you want to capture.\n",
    "        \n",
    "        - operation : `str`\n",
    "            - It represents the aggregation operation you want to perform.(By default it is SUM)\n",
    "    \"\"\"\n",
    "    feat_1 = feat_name + \"_Insc_ReImb_Amt\"\n",
    "    train_iobp_df[feat_1] = train_iobp_df.groupby(grp_col)['InscClaimAmtReimbursed'].transform(operation)\n",
    "\n",
    "    feat_2 = feat_name + \"_CoPayment\"\n",
    "    train_iobp_df[feat_2] = train_iobp_df.groupby(grp_col)['DeductibleAmtPaid'].transform(operation)\n",
    "\n",
    "    feat_3 = feat_name + \"_IP_Annual_ReImb_Amt\"\n",
    "    train_iobp_df[feat_3] = train_iobp_df.groupby(grp_col)['IPAnnualReimbursementAmt'].transform(operation)\n",
    "\n",
    "    feat_4 = feat_name + \"_IP_Annual_Ded_Amt\"\n",
    "    train_iobp_df[feat_4] = train_iobp_df.groupby(grp_col)['IPAnnualDeductibleAmt'].transform(operation)\n",
    "\n",
    "    feat_5 = feat_name + \"_OP_Annual_ReImb_Amt\"\n",
    "    train_iobp_df[feat_5] = train_iobp_df.groupby(grp_col)['OPAnnualReimbursementAmt'].transform(operation)\n",
    "\n",
    "    feat_6 = feat_name + \"_OP_Annual_Ded_Amt\"\n",
    "    train_iobp_df[feat_6] = train_iobp_df.groupby(grp_col)['OPAnnualDeductibleAmt'].transform(operation)\n",
    "\n",
    "    feat_7 = feat_name + \"_Admit_Duration\"\n",
    "    train_iobp_df[feat_7] = train_iobp_df.groupby(grp_col)['Admitted_Duration'].transform(operation)\n",
    "\n",
    "    feat_8 = feat_name + \"_Claim_Duration\"\n",
    "    train_iobp_df[feat_8] = train_iobp_df.groupby(grp_col)['Claim_Duration'].transform(operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "cb59029d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_6] = train_iobp_df.groupby(grp_col)['OPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_7] = train_iobp_df.groupby(grp_col)['Admitted_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_8] = train_iobp_df.groupby(grp_col)['Claim_Duration'].transform(operation)\n"
     ]
    }
   ],
   "source": [
    "# BENE, PHYs, Diagnosis Admit and Group Codes columns\n",
    "create_agg_feats(grp_col='BeneID', feat_name=\"BENE\")\n",
    "create_agg_feats(grp_col='AttendingPhysician', feat_name=\"ATT_PHY\")\n",
    "create_agg_feats(grp_col='OperatingPhysician', feat_name=\"OPT_PHY\")\n",
    "create_agg_feats(grp_col='OtherPhysician', feat_name=\"OTH_PHY\")\n",
    "create_agg_feats(grp_col='ClmAdmitDiagnosisCode', feat_name=\"Claim_Admit_Diag_Code\")\n",
    "create_agg_feats(grp_col='DiagnosisGroupCode', feat_name=\"Diag_GCode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d73b7ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping these 3 columns as there 99% of values are same\n",
    "train_iobp_df.drop(['ClmProcedureCode_4', 'ClmProcedureCode_5', 'ClmProcedureCode_6'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ba9497fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_1] = train_iobp_df.groupby(grp_col)['InscClaimAmtReimbursed'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_2] = train_iobp_df.groupby(grp_col)['DeductibleAmtPaid'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_3] = train_iobp_df.groupby(grp_col)['IPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_4] = train_iobp_df.groupby(grp_col)['IPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_5] = train_iobp_df.groupby(grp_col)['OPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_6] = train_iobp_df.groupby(grp_col)['OPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_7] = train_iobp_df.groupby(grp_col)['Admitted_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_8] = train_iobp_df.groupby(grp_col)['Claim_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_1] = train_iobp_df.groupby(grp_col)['InscClaimAmtReimbursed'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_2] = train_iobp_df.groupby(grp_col)['DeductibleAmtPaid'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_3] = train_iobp_df.groupby(grp_col)['IPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_4] = train_iobp_df.groupby(grp_col)['IPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_5] = train_iobp_df.groupby(grp_col)['OPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_6] = train_iobp_df.groupby(grp_col)['OPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_7] = train_iobp_df.groupby(grp_col)['Admitted_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_8] = train_iobp_df.groupby(grp_col)['Claim_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_1] = train_iobp_df.groupby(grp_col)['InscClaimAmtReimbursed'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_2] = train_iobp_df.groupby(grp_col)['DeductibleAmtPaid'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_3] = train_iobp_df.groupby(grp_col)['IPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_4] = train_iobp_df.groupby(grp_col)['IPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_5] = train_iobp_df.groupby(grp_col)['OPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_6] = train_iobp_df.groupby(grp_col)['OPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_7] = train_iobp_df.groupby(grp_col)['Admitted_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_8] = train_iobp_df.groupby(grp_col)['Claim_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_1] = train_iobp_df.groupby(grp_col)['InscClaimAmtReimbursed'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_2] = train_iobp_df.groupby(grp_col)['DeductibleAmtPaid'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_3] = train_iobp_df.groupby(grp_col)['IPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_4] = train_iobp_df.groupby(grp_col)['IPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_5] = train_iobp_df.groupby(grp_col)['OPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_6] = train_iobp_df.groupby(grp_col)['OPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_7] = train_iobp_df.groupby(grp_col)['Admitted_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_8] = train_iobp_df.groupby(grp_col)['Claim_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_1] = train_iobp_df.groupby(grp_col)['InscClaimAmtReimbursed'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_2] = train_iobp_df.groupby(grp_col)['DeductibleAmtPaid'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_3] = train_iobp_df.groupby(grp_col)['IPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_4] = train_iobp_df.groupby(grp_col)['IPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_5] = train_iobp_df.groupby(grp_col)['OPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_6] = train_iobp_df.groupby(grp_col)['OPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_7] = train_iobp_df.groupby(grp_col)['Admitted_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_8] = train_iobp_df.groupby(grp_col)['Claim_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_1] = train_iobp_df.groupby(grp_col)['InscClaimAmtReimbursed'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_2] = train_iobp_df.groupby(grp_col)['DeductibleAmtPaid'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_3] = train_iobp_df.groupby(grp_col)['IPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_4] = train_iobp_df.groupby(grp_col)['IPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_5] = train_iobp_df.groupby(grp_col)['OPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_6] = train_iobp_df.groupby(grp_col)['OPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_7] = train_iobp_df.groupby(grp_col)['Admitted_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_8] = train_iobp_df.groupby(grp_col)['Claim_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_1] = train_iobp_df.groupby(grp_col)['InscClaimAmtReimbursed'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_2] = train_iobp_df.groupby(grp_col)['DeductibleAmtPaid'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_3] = train_iobp_df.groupby(grp_col)['IPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_4] = train_iobp_df.groupby(grp_col)['IPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_5] = train_iobp_df.groupby(grp_col)['OPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_6] = train_iobp_df.groupby(grp_col)['OPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_7] = train_iobp_df.groupby(grp_col)['Admitted_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_8] = train_iobp_df.groupby(grp_col)['Claim_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_1] = train_iobp_df.groupby(grp_col)['InscClaimAmtReimbursed'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_2] = train_iobp_df.groupby(grp_col)['DeductibleAmtPaid'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_3] = train_iobp_df.groupby(grp_col)['IPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_4] = train_iobp_df.groupby(grp_col)['IPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_5] = train_iobp_df.groupby(grp_col)['OPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_6] = train_iobp_df.groupby(grp_col)['OPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_7] = train_iobp_df.groupby(grp_col)['Admitted_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_8] = train_iobp_df.groupby(grp_col)['Claim_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_1] = train_iobp_df.groupby(grp_col)['InscClaimAmtReimbursed'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_2] = train_iobp_df.groupby(grp_col)['DeductibleAmtPaid'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_3] = train_iobp_df.groupby(grp_col)['IPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_4] = train_iobp_df.groupby(grp_col)['IPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_5] = train_iobp_df.groupby(grp_col)['OPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_6] = train_iobp_df.groupby(grp_col)['OPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_7] = train_iobp_df.groupby(grp_col)['Admitted_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_8] = train_iobp_df.groupby(grp_col)['Claim_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_1] = train_iobp_df.groupby(grp_col)['InscClaimAmtReimbursed'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_2] = train_iobp_df.groupby(grp_col)['DeductibleAmtPaid'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_3] = train_iobp_df.groupby(grp_col)['IPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_4] = train_iobp_df.groupby(grp_col)['IPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_5] = train_iobp_df.groupby(grp_col)['OPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_6] = train_iobp_df.groupby(grp_col)['OPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_7] = train_iobp_df.groupby(grp_col)['Admitted_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_8] = train_iobp_df.groupby(grp_col)['Claim_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_1] = train_iobp_df.groupby(grp_col)['InscClaimAmtReimbursed'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_2] = train_iobp_df.groupby(grp_col)['DeductibleAmtPaid'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_3] = train_iobp_df.groupby(grp_col)['IPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_4] = train_iobp_df.groupby(grp_col)['IPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_5] = train_iobp_df.groupby(grp_col)['OPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_6] = train_iobp_df.groupby(grp_col)['OPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_7] = train_iobp_df.groupby(grp_col)['Admitted_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_8] = train_iobp_df.groupby(grp_col)['Claim_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_1] = train_iobp_df.groupby(grp_col)['InscClaimAmtReimbursed'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_2] = train_iobp_df.groupby(grp_col)['DeductibleAmtPaid'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_3] = train_iobp_df.groupby(grp_col)['IPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_4] = train_iobp_df.groupby(grp_col)['IPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_5] = train_iobp_df.groupby(grp_col)['OPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_6] = train_iobp_df.groupby(grp_col)['OPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_7] = train_iobp_df.groupby(grp_col)['Admitted_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_8] = train_iobp_df.groupby(grp_col)['Claim_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_1] = train_iobp_df.groupby(grp_col)['InscClaimAmtReimbursed'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_2] = train_iobp_df.groupby(grp_col)['DeductibleAmtPaid'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_3] = train_iobp_df.groupby(grp_col)['IPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_4] = train_iobp_df.groupby(grp_col)['IPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_5] = train_iobp_df.groupby(grp_col)['OPAnnualReimbursementAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_6] = train_iobp_df.groupby(grp_col)['OPAnnualDeductibleAmt'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_7] = train_iobp_df.groupby(grp_col)['Admitted_Duration'].transform(operation)\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3303470680.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[feat_8] = train_iobp_df.groupby(grp_col)['Claim_Duration'].transform(operation)\n"
     ]
    }
   ],
   "source": [
    "# Diagnosis Codes columns\n",
    "create_agg_feats(grp_col='ClmDiagnosisCode_1', feat_name=\"Claim_DiagCode1\")\n",
    "create_agg_feats(grp_col='ClmDiagnosisCode_2', feat_name=\"Claim_DiagCode2\")\n",
    "create_agg_feats(grp_col='ClmDiagnosisCode_3', feat_name=\"Claim_DiagCode3\")\n",
    "create_agg_feats(grp_col='ClmDiagnosisCode_4', feat_name=\"Claim_DiagCode4\")\n",
    "create_agg_feats(grp_col='ClmDiagnosisCode_5', feat_name=\"Claim_DiagCode5\")\n",
    "create_agg_feats(grp_col='ClmDiagnosisCode_6', feat_name=\"Claim_DiagCode6\")\n",
    "create_agg_feats(grp_col='ClmDiagnosisCode_7', feat_name=\"Claim_DiagCode7\")\n",
    "create_agg_feats(grp_col='ClmDiagnosisCode_8', feat_name=\"Claim_DiagCode8\")\n",
    "create_agg_feats(grp_col='ClmDiagnosisCode_9', feat_name=\"Claim_DiagCode9\")\n",
    "create_agg_feats(grp_col='ClmDiagnosisCode_10', feat_name=\"Claim_DiagCode10\")\n",
    "\n",
    "# Medical Procedure Codes columns\n",
    "create_agg_feats(grp_col='ClmProcedureCode_1', feat_name=\"Claim_ProcCode1\")\n",
    "create_agg_feats(grp_col='ClmProcedureCode_2', feat_name=\"Claim_ProcCode2\")\n",
    "create_agg_feats(grp_col='ClmProcedureCode_3', feat_name=\"Claim_ProcCode3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "865ba1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider\"]=train_iobp_df.groupby(['Provider'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID\"]=train_iobp_df.groupby(['Provider','BeneID'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_AttendingPhysician\"]=train_iobp_df.groupby(['Provider','AttendingPhysician'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_OtherPhysician\"]=train_iobp_df.groupby(['Provider','OtherPhysician'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_OperatingPhysician\"]=train_iobp_df.groupby(['Provider','OperatingPhysician'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_ClmAdmitDiagnosisCode\"]=train_iobp_df.groupby(['Provider','ClmAdmitDiagnosisCode'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_1\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_2\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_3\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_4\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_4'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_5\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_5'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_6\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_6'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_7\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_7'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_8\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_8'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_9\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_9'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_10\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_10'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_DiagnosisGroupCode\"]=train_iobp_df.groupby(['Provider','DiagnosisGroupCode'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_4\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_4'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_5\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_5'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_6\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_6'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_7\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_7'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_8\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_8'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_9\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_9'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_10\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_10'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:57: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:58: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_4\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_4'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_5\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_5'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_6\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_6'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_7\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_7'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_8\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_8'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_9\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_9'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_10\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_10'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_4\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_4'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_5\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_5'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_6\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_6'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_7\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_7'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_8\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_8'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_9\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_9'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:77: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_10\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_10'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:86: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:88: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_4\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_4'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_5\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_5'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_6\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_6'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_7\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_7'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:92: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_8\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_8'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_9\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_9'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_10\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_10'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_1_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_1','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_1_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_1','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_1_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_1','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_2_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_2','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_2_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_2','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_2_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_2','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_3_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_3','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_3_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_3','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_3_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_3','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:106: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_4_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_4','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_4_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_4','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_4_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_4','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_5_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_5','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:110: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_5_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_5','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:111: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_5_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_5','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:112: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_6_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_6','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:113: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_6_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_6','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_6_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_6','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:115: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_7_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_7','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_7_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_7','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_7_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_7','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:118: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_8_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_8','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_8_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_8','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_8_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_8','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_9_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_9','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_9_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_9','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_9_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_9','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:124: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_10_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_10','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_10_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_10','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\3993359952.py:126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_10_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_10','ClmProcedureCode_3'])['ClaimID'].transform('count')\n"
     ]
    }
   ],
   "source": [
    "# PROVIDER <--> other features :: To get claim counts\n",
    "train_iobp_df[\"ClmCount_Provider\"]=train_iobp_df.groupby(['Provider'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID\"]=train_iobp_df.groupby(['Provider','BeneID'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_AttendingPhysician\"]=train_iobp_df.groupby(['Provider','AttendingPhysician'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_OtherPhysician\"]=train_iobp_df.groupby(['Provider','OtherPhysician'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_OperatingPhysician\"]=train_iobp_df.groupby(['Provider','OperatingPhysician'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_ClmAdmitDiagnosisCode\"]=train_iobp_df.groupby(['Provider','ClmAdmitDiagnosisCode'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_1\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_2\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_3\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_3'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_4\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_4'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_5\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_5'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_6\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_6'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_7\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_7'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_8\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_8'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_9\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_9'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_ClmDiagnosisCode_10\"]=train_iobp_df.groupby(['Provider','ClmDiagnosisCode_10'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_DiagnosisGroupCode\"]=train_iobp_df.groupby(['Provider','DiagnosisGroupCode'])['ClaimID'].transform('count')\n",
    "\n",
    "# PROVIDER <--> BENE <--> PHYSICIANS :: To get claim counts\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician'])['ClaimID'].transform('count')\n",
    "\n",
    "# PROVIDER <--> BENE <--> ATTENDING PHYSICIAN <--> PROCEDURE CODES :: To get claim counts\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
    "\n",
    "# PROVIDER <--> BENE <--> OPERATING PHYSICIAN <--> PROCEDURE CODES :: To get claim counts\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
    "\n",
    "# PROVIDER <--> BENE <--> OTHER PHYSICIAN <--> PROCEDURE CODES :: To get claim counts\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
    "\n",
    "# PROVIDER <--> BENE <--> ATTENDING PHYSICIAN <--> DIAGNOSIS CODES :: To get claim counts\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_3'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_4\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_4'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_5\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_5'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_6\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_6'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_7\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_7'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_8\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_8'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_9\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_9'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_10\"]=train_iobp_df.groupby(['Provider','BeneID','AttendingPhysician','ClmDiagnosisCode_10'])['ClaimID'].transform('count')\n",
    "\n",
    "# PROVIDER <--> BENE <--> OPERATING PHYSICIAN <--> DIAGNOSIS CODES :: To get claim counts\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_3'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_4\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_4'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_5\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_5'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_6\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_6'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_7\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_7'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_8\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_8'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_9\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_9'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_10\"]=train_iobp_df.groupby(['Provider','BeneID','OperatingPhysician','ClmDiagnosisCode_10'])['ClaimID'].transform('count')\n",
    "\n",
    "# PROVIDER <--> BENE <--> OTHER PHYSICIAN <--> DIAGNOSIS CODES :: To get claim counts\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_3'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_4\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_4'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_5\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_5'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_6\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_6'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_7\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_7'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_8\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_8'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_9\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_9'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_10\"]=train_iobp_df.groupby(['Provider','BeneID','OtherPhysician','ClmDiagnosisCode_10'])['ClaimID'].transform('count')\n",
    "\n",
    "# PROVIDER <--> BENE <--> PROCEDURE CODES :: To get claim counts\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
    "\n",
    "# PROVIDER <--> BENE <--> DIAGNOSIS CODES :: To get claim counts\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_3'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_4\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_4'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_5\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_5'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_6\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_6'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_7\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_7'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_8\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_8'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_9\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_9'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_10\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_10'])['ClaimID'].transform('count')\n",
    "\n",
    "# PROVIDER <--> BENE <--> DIAGNOSIS CODES <--> PROCEDURE CODES :: To get claim counts\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_1_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_1','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_1_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_1','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_1_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_1','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_2_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_2','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_2_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_2','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_2_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_2','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_3_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_3','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_3_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_3','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_3_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_3','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_4_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_4','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_4_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_4','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_4_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_4','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_5_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_5','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_5_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_5','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_5_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_5','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_6_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_6','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_6_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_6','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_6_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_6','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_7_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_7','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_7_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_7','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_7_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_7','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_8_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_8','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_8_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_8','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_8_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_8','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_9_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_9','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_9_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_9','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_9_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_9','ClmProcedureCode_3'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_10_ClmProcedureCode_1\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_10','ClmProcedureCode_1'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_10_ClmProcedureCode_2\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_10','ClmProcedureCode_2'])['ClaimID'].transform('count')\n",
    "train_iobp_df[\"ClmCount_Provider_BeneID_ClmDiagnosisCode_10_ClmProcedureCode_3\"]=train_iobp_df.groupby(['Provider','BeneID','ClmDiagnosisCode_10','ClmProcedureCode_3'])['ClaimID'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ee3bb7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unwanted columns\n",
    "remove_unwanted_columns=['BeneID', 'ClaimID', 'ClaimStartDt','ClaimEndDt','AttendingPhysician','OperatingPhysician', 'OtherPhysician',\n",
    "                      'AdmissionDt', 'ClmAdmitDiagnosisCode', 'DischargeDt', 'DiagnosisGroupCode',\n",
    "                      'ClmDiagnosisCode_1', 'ClmDiagnosisCode_2', 'ClmDiagnosisCode_3', 'ClmDiagnosisCode_4', 'ClmDiagnosisCode_5', \n",
    "                      'ClmDiagnosisCode_6', 'ClmDiagnosisCode_7', 'ClmDiagnosisCode_8', 'ClmDiagnosisCode_9', 'ClmDiagnosisCode_10',\n",
    "                      'ClmProcedureCode_1', 'ClmProcedureCode_2', 'ClmProcedureCode_3', 'DOB', 'DOD', 'State', 'County']\n",
    "\n",
    "train_iobp_df.drop(columns=remove_unwanted_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "79c276a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Nulls in Deductible Amt Paid by Patient\n",
    "train_iobp_df['DeductibleAmtPaid'].fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8e7a1e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary encoding the categorical features --> 0 means No and 1 means Yes\n",
    "train_iobp_df['Gender'] = train_iobp_df['Gender'].apply(lambda val: 0 if val == 2 else val)\n",
    "train_iobp_df['PotentialFraud'] = train_iobp_df['PotentialFraud'].apply(lambda val: 0 if val == \"No\" else 1)\n",
    "train_iobp_df['Is_Alive?'] = train_iobp_df['Is_Alive?'].apply(lambda val: 0 if val == \"No\" else 1)\n",
    "\n",
    "train_iobp_df['ChronicCond_Alzheimer'] = train_iobp_df['ChronicCond_Alzheimer'].apply(lambda val: 0 if val == 2 else val)\n",
    "train_iobp_df['ChronicCond_Heartfailure'] = train_iobp_df['ChronicCond_Heartfailure'].apply(lambda val: 0 if val == 2 else val)\n",
    "train_iobp_df['ChronicCond_KidneyDisease'] = train_iobp_df['ChronicCond_KidneyDisease'].apply(lambda val: 0 if val == 2 else val)\n",
    "train_iobp_df['ChronicCond_Cancer'] = train_iobp_df['ChronicCond_Cancer'].apply(lambda val: 0 if val == 2 else val)\n",
    "train_iobp_df['ChronicCond_ObstrPulmonary'] = train_iobp_df['ChronicCond_ObstrPulmonary'].apply(lambda val: 0 if val == 2 else val)\n",
    "train_iobp_df['ChronicCond_Depression'] = train_iobp_df['ChronicCond_Depression'].apply(lambda val: 0 if val == 2 else val)\n",
    "train_iobp_df['ChronicCond_Diabetes'] = train_iobp_df['ChronicCond_Diabetes'].apply(lambda val: 0 if val == 2 else val)\n",
    "train_iobp_df['ChronicCond_IschemicHeart'] = train_iobp_df['ChronicCond_IschemicHeart'].apply(lambda val: 0 if val == 2 else val)\n",
    "train_iobp_df['ChronicCond_Osteoporasis'] = train_iobp_df['ChronicCond_Osteoporasis'].apply(lambda val: 0 if val == 2 else val)\n",
    "train_iobp_df['ChronicCond_rheumatoidarthritis'] = train_iobp_df['ChronicCond_rheumatoidarthritis'].apply(lambda val: 0 if val == 2 else val)\n",
    "train_iobp_df['ChronicCond_stroke'] = train_iobp_df['ChronicCond_stroke'].apply(lambda val: 0 if val == 2 else val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d219c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the Categorical features\n",
    "train_iobp_df = pd.get_dummies(train_iobp_df,columns=['Gender', 'Race', 'Admitted?', 'Is_Alive?'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6a5c81d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Nulls in the aggregated features\n",
    "train_iobp_df.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "25b81447",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\2962834618.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df = train_iobp_df.groupby(['Provider','PotentialFraud'],as_index=False).agg('sum')\n",
      "C:\\Users\\Ahzam.Imam\\AppData\\Local\\Temp\\ipykernel_22844\\2962834618.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_iobp_df = train_iobp_df.groupby(['Provider','PotentialFraud'],as_index=False).agg('sum')\n"
     ]
    }
   ],
   "source": [
    "train_iobp_df = train_iobp_df.groupby(['Provider','PotentialFraud'],as_index=False).agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ba8fd25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_iobp_df.drop(axis=1, columns=['Provider','PotentialFraud'])\n",
    "y = train_iobp_df['PotentialFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "32fe879e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   InscClaimAmtReimbursed  DeductibleAmtPaid  RenalDiseaseIndicator  \\\n",
      "0                   26000             1068.0                      0   \n",
      "\n",
      "   ChronicCond_Alzheimer  ChronicCond_Heartfailure  ChronicCond_KidneyDisease  \\\n",
      "0                      1                         0                          1   \n",
      "\n",
      "   ChronicCond_Cancer  ChronicCond_ObstrPulmonary  ChronicCond_Depression  \\\n",
      "0                   0                           0                       1   \n",
      "\n",
      "   ChronicCond_Diabetes  ChronicCond_IschemicHeart  ChronicCond_Osteoporasis  \\\n",
      "0                     1                          1                         0   \n",
      "\n",
      "   ChronicCond_rheumatoidarthritis  ChronicCond_stroke  \\\n",
      "0                                1                   1   \n",
      "\n",
      "   IPAnnualReimbursementAmt  IPAnnualDeductibleAmt  OPAnnualReimbursementAmt  \\\n",
      "0                     36000                   3204                        60   \n",
      "\n",
      "   OPAnnualDeductibleAmt  Claim_Duration  Admitted_Duration  Bene_Age  \\\n",
      "0                     70               6                  6       0.0   \n",
      "\n",
      "   Att_Opr_Oth_Phy_Tot_Claims  Prv_Tot_Att_Opr_Oth_Phys  PRV_Tot_Admit_DCodes  \\\n",
      "0                         1.0                         1                     1   \n",
      "\n",
      "   PRV_Tot_DGrpCodes  PRV_Tot_Unq_DOB_Years  PRV_Bene_Age_Sum  \\\n",
      "0                  1                      1               0.0   \n",
      "\n",
      "   PRV_Insc_Clm_ReImb_Amt  PRV_Tot_RKD_Patients  PRV_CoPayment  \\\n",
      "0                   26000                     0         1068.0   \n",
      "\n",
      "   PRV_IP_Annual_ReImb_Amt  PRV_IP_Annual_Ded_Amt  PRV_OP_Annual_ReImb_Amt  \\\n",
      "0                    36000                   3204                       60   \n",
      "\n",
      "   PRV_OP_Annual_Ded_Amt  PRV_Admit_Duration  PRV_Claim_Duration  \\\n",
      "0                     70                   6                   6   \n",
      "\n",
      "   BENE_Insc_ReImb_Amt  BENE_CoPayment  BENE_IP_Annual_ReImb_Amt  \\\n",
      "0                26000          1068.0                     36000   \n",
      "\n",
      "   BENE_IP_Annual_Ded_Amt  BENE_OP_Annual_ReImb_Amt  BENE_OP_Annual_Ded_Amt  \\\n",
      "0                    3204                        60                      70   \n",
      "\n",
      "   BENE_Admit_Duration  BENE_Claim_Duration  ATT_PHY_Insc_ReImb_Amt  \\\n",
      "0                    6                    6                   26000   \n",
      "\n",
      "   ATT_PHY_CoPayment  ATT_PHY_IP_Annual_ReImb_Amt  ATT_PHY_IP_Annual_Ded_Amt  \\\n",
      "0             1068.0                        36000                       3204   \n",
      "\n",
      "   ATT_PHY_OP_Annual_ReImb_Amt  ATT_PHY_OP_Annual_Ded_Amt  \\\n",
      "0                           60                         70   \n",
      "\n",
      "   ATT_PHY_Admit_Duration  ATT_PHY_Claim_Duration  OPT_PHY_Insc_ReImb_Amt  \\\n",
      "0                       6                       6                     0.0   \n",
      "\n",
      "   OPT_PHY_CoPayment  OPT_PHY_IP_Annual_ReImb_Amt  OPT_PHY_IP_Annual_Ded_Amt  \\\n",
      "0                0.0                          0.0                        0.0   \n",
      "\n",
      "   OPT_PHY_OP_Annual_ReImb_Amt  OPT_PHY_OP_Annual_Ded_Amt  \\\n",
      "0                          0.0                        0.0   \n",
      "\n",
      "   OPT_PHY_Admit_Duration  OPT_PHY_Claim_Duration  OTH_PHY_Insc_ReImb_Amt  \\\n",
      "0                     0.0                     0.0                     0.0   \n",
      "\n",
      "   OTH_PHY_CoPayment  OTH_PHY_IP_Annual_ReImb_Amt  OTH_PHY_IP_Annual_Ded_Amt  \\\n",
      "0                0.0                          0.0                        0.0   \n",
      "\n",
      "   OTH_PHY_OP_Annual_ReImb_Amt  OTH_PHY_OP_Annual_Ded_Amt  \\\n",
      "0                          0.0                        0.0   \n",
      "\n",
      "   OTH_PHY_Admit_Duration  OTH_PHY_Claim_Duration  \\\n",
      "0                     0.0                     0.0   \n",
      "\n",
      "   Claim_Admit_Diag_Code_Insc_ReImb_Amt  Claim_Admit_Diag_Code_CoPayment  \\\n",
      "0                                 26000                           1068.0   \n",
      "\n",
      "   Claim_Admit_Diag_Code_IP_Annual_ReImb_Amt  \\\n",
      "0                                      36000   \n",
      "\n",
      "   Claim_Admit_Diag_Code_IP_Annual_Ded_Amt  \\\n",
      "0                                     3204   \n",
      "\n",
      "   Claim_Admit_Diag_Code_OP_Annual_ReImb_Amt  \\\n",
      "0                                         60   \n",
      "\n",
      "   Claim_Admit_Diag_Code_OP_Annual_Ded_Amt  \\\n",
      "0                                       70   \n",
      "\n",
      "   Claim_Admit_Diag_Code_Admit_Duration  Claim_Admit_Diag_Code_Claim_Duration  \\\n",
      "0                                     6                                     6   \n",
      "\n",
      "   Diag_GCode_Insc_ReImb_Amt  Diag_GCode_CoPayment  \\\n",
      "0                      26000                1068.0   \n",
      "\n",
      "   Diag_GCode_IP_Annual_ReImb_Amt  Diag_GCode_IP_Annual_Ded_Amt  \\\n",
      "0                           36000                          3204   \n",
      "\n",
      "   Diag_GCode_OP_Annual_ReImb_Amt  Diag_GCode_OP_Annual_Ded_Amt  \\\n",
      "0                              60                            70   \n",
      "\n",
      "   Diag_GCode_Admit_Duration  Diag_GCode_Claim_Duration  \\\n",
      "0                          6                          6   \n",
      "\n",
      "   Claim_DiagCode1_Insc_ReImb_Amt  Claim_DiagCode1_CoPayment  \\\n",
      "0                           26000                     1068.0   \n",
      "\n",
      "   Claim_DiagCode1_IP_Annual_ReImb_Amt  Claim_DiagCode1_IP_Annual_Ded_Amt  \\\n",
      "0                                36000                               3204   \n",
      "\n",
      "   Claim_DiagCode1_OP_Annual_ReImb_Amt  Claim_DiagCode1_OP_Annual_Ded_Amt  \\\n",
      "0                                   60                                 70   \n",
      "\n",
      "   Claim_DiagCode1_Admit_Duration  Claim_DiagCode1_Claim_Duration  \\\n",
      "0                               6                               6   \n",
      "\n",
      "   Claim_DiagCode2_Insc_ReImb_Amt  Claim_DiagCode2_CoPayment  \\\n",
      "0                           26000                     1068.0   \n",
      "\n",
      "   Claim_DiagCode2_IP_Annual_ReImb_Amt  Claim_DiagCode2_IP_Annual_Ded_Amt  \\\n",
      "0                                36000                               3204   \n",
      "\n",
      "   Claim_DiagCode2_OP_Annual_ReImb_Amt  Claim_DiagCode2_OP_Annual_Ded_Amt  \\\n",
      "0                                   60                                 70   \n",
      "\n",
      "   Claim_DiagCode2_Admit_Duration  Claim_DiagCode2_Claim_Duration  \\\n",
      "0                               6                               6   \n",
      "\n",
      "   Claim_DiagCode3_Insc_ReImb_Amt  Claim_DiagCode3_CoPayment  \\\n",
      "0                           26000                     1068.0   \n",
      "\n",
      "   Claim_DiagCode3_IP_Annual_ReImb_Amt  Claim_DiagCode3_IP_Annual_Ded_Amt  \\\n",
      "0                                36000                               3204   \n",
      "\n",
      "   Claim_DiagCode3_OP_Annual_ReImb_Amt  Claim_DiagCode3_OP_Annual_Ded_Amt  \\\n",
      "0                                   60                                 70   \n",
      "\n",
      "   Claim_DiagCode3_Admit_Duration  Claim_DiagCode3_Claim_Duration  \\\n",
      "0                               6                               6   \n",
      "\n",
      "   Claim_DiagCode4_Insc_ReImb_Amt  Claim_DiagCode4_CoPayment  \\\n",
      "0                           26000                     1068.0   \n",
      "\n",
      "   Claim_DiagCode4_IP_Annual_ReImb_Amt  Claim_DiagCode4_IP_Annual_Ded_Amt  \\\n",
      "0                                36000                               3204   \n",
      "\n",
      "   Claim_DiagCode4_OP_Annual_ReImb_Amt  Claim_DiagCode4_OP_Annual_Ded_Amt  \\\n",
      "0                                   60                                 70   \n",
      "\n",
      "   Claim_DiagCode4_Admit_Duration  Claim_DiagCode4_Claim_Duration  \\\n",
      "0                               6                               6   \n",
      "\n",
      "   Claim_DiagCode5_Insc_ReImb_Amt  Claim_DiagCode5_CoPayment  \\\n",
      "0                           26000                     1068.0   \n",
      "\n",
      "   Claim_DiagCode5_IP_Annual_ReImb_Amt  Claim_DiagCode5_IP_Annual_Ded_Amt  \\\n",
      "0                                36000                               3204   \n",
      "\n",
      "   Claim_DiagCode5_OP_Annual_ReImb_Amt  Claim_DiagCode5_OP_Annual_Ded_Amt  \\\n",
      "0                                   60                                 70   \n",
      "\n",
      "   Claim_DiagCode5_Admit_Duration  Claim_DiagCode5_Claim_Duration  \\\n",
      "0                               6                               6   \n",
      "\n",
      "   Claim_DiagCode6_Insc_ReImb_Amt  Claim_DiagCode6_CoPayment  \\\n",
      "0                           26000                     1068.0   \n",
      "\n",
      "   Claim_DiagCode6_IP_Annual_ReImb_Amt  Claim_DiagCode6_IP_Annual_Ded_Amt  \\\n",
      "0                                36000                               3204   \n",
      "\n",
      "   Claim_DiagCode6_OP_Annual_ReImb_Amt  Claim_DiagCode6_OP_Annual_Ded_Amt  \\\n",
      "0                                   60                                 70   \n",
      "\n",
      "   Claim_DiagCode6_Admit_Duration  Claim_DiagCode6_Claim_Duration  \\\n",
      "0                               6                               6   \n",
      "\n",
      "   Claim_DiagCode7_Insc_ReImb_Amt  Claim_DiagCode7_CoPayment  \\\n",
      "0                           26000                     1068.0   \n",
      "\n",
      "   Claim_DiagCode7_IP_Annual_ReImb_Amt  Claim_DiagCode7_IP_Annual_Ded_Amt  \\\n",
      "0                                36000                               3204   \n",
      "\n",
      "   Claim_DiagCode7_OP_Annual_ReImb_Amt  Claim_DiagCode7_OP_Annual_Ded_Amt  \\\n",
      "0                                   60                                 70   \n",
      "\n",
      "   Claim_DiagCode7_Admit_Duration  Claim_DiagCode7_Claim_Duration  \\\n",
      "0                               6                               6   \n",
      "\n",
      "   Claim_DiagCode8_Insc_ReImb_Amt  Claim_DiagCode8_CoPayment  \\\n",
      "0                           26000                     1068.0   \n",
      "\n",
      "   Claim_DiagCode8_IP_Annual_ReImb_Amt  Claim_DiagCode8_IP_Annual_Ded_Amt  \\\n",
      "0                                36000                               3204   \n",
      "\n",
      "   Claim_DiagCode8_OP_Annual_ReImb_Amt  Claim_DiagCode8_OP_Annual_Ded_Amt  \\\n",
      "0                                   60                                 70   \n",
      "\n",
      "   Claim_DiagCode8_Admit_Duration  Claim_DiagCode8_Claim_Duration  \\\n",
      "0                               6                               6   \n",
      "\n",
      "   Claim_DiagCode9_Insc_ReImb_Amt  Claim_DiagCode9_CoPayment  \\\n",
      "0                           26000                     1068.0   \n",
      "\n",
      "   Claim_DiagCode9_IP_Annual_ReImb_Amt  Claim_DiagCode9_IP_Annual_Ded_Amt  \\\n",
      "0                                36000                               3204   \n",
      "\n",
      "   Claim_DiagCode9_OP_Annual_ReImb_Amt  Claim_DiagCode9_OP_Annual_Ded_Amt  \\\n",
      "0                                   60                                 70   \n",
      "\n",
      "   Claim_DiagCode9_Admit_Duration  Claim_DiagCode9_Claim_Duration  \\\n",
      "0                               6                               6   \n",
      "\n",
      "   Claim_DiagCode10_Insc_ReImb_Amt  Claim_DiagCode10_CoPayment  \\\n",
      "0                              0.0                         0.0   \n",
      "\n",
      "   Claim_DiagCode10_IP_Annual_ReImb_Amt  Claim_DiagCode10_IP_Annual_Ded_Amt  \\\n",
      "0                                   0.0                                 0.0   \n",
      "\n",
      "   Claim_DiagCode10_OP_Annual_ReImb_Amt  Claim_DiagCode10_OP_Annual_Ded_Amt  \\\n",
      "0                                   0.0                                 0.0   \n",
      "\n",
      "   Claim_DiagCode10_Admit_Duration  Claim_DiagCode10_Claim_Duration  \\\n",
      "0                              0.0                              0.0   \n",
      "\n",
      "   Claim_ProcCode1_Insc_ReImb_Amt  Claim_ProcCode1_CoPayment  \\\n",
      "0                             0.0                        0.0   \n",
      "\n",
      "   Claim_ProcCode1_IP_Annual_ReImb_Amt  Claim_ProcCode1_IP_Annual_Ded_Amt  \\\n",
      "0                                  0.0                                0.0   \n",
      "\n",
      "   Claim_ProcCode1_OP_Annual_ReImb_Amt  Claim_ProcCode1_OP_Annual_Ded_Amt  \\\n",
      "0                                  0.0                                0.0   \n",
      "\n",
      "   Claim_ProcCode1_Admit_Duration  Claim_ProcCode1_Claim_Duration  \\\n",
      "0                             0.0                             0.0   \n",
      "\n",
      "   Claim_ProcCode2_Insc_ReImb_Amt  Claim_ProcCode2_CoPayment  \\\n",
      "0                             0.0                        0.0   \n",
      "\n",
      "   Claim_ProcCode2_IP_Annual_ReImb_Amt  Claim_ProcCode2_IP_Annual_Ded_Amt  \\\n",
      "0                                  0.0                                0.0   \n",
      "\n",
      "   Claim_ProcCode2_OP_Annual_ReImb_Amt  Claim_ProcCode2_OP_Annual_Ded_Amt  \\\n",
      "0                                  0.0                                0.0   \n",
      "\n",
      "   Claim_ProcCode2_Admit_Duration  Claim_ProcCode2_Claim_Duration  \\\n",
      "0                             0.0                             0.0   \n",
      "\n",
      "   Claim_ProcCode3_Insc_ReImb_Amt  Claim_ProcCode3_CoPayment  \\\n",
      "0                             0.0                        0.0   \n",
      "\n",
      "   Claim_ProcCode3_IP_Annual_ReImb_Amt  Claim_ProcCode3_IP_Annual_Ded_Amt  \\\n",
      "0                                  0.0                                0.0   \n",
      "\n",
      "   Claim_ProcCode3_OP_Annual_ReImb_Amt  Claim_ProcCode3_OP_Annual_Ded_Amt  \\\n",
      "0                                  0.0                                0.0   \n",
      "\n",
      "   Claim_ProcCode3_Admit_Duration  Claim_ProcCode3_Claim_Duration  \\\n",
      "0                             0.0                             0.0   \n",
      "\n",
      "   ClmCount_Provider  ClmCount_Provider_BeneID  \\\n",
      "0                  1                         1   \n",
      "\n",
      "   ClmCount_Provider_AttendingPhysician  ClmCount_Provider_OtherPhysician  \\\n",
      "0                                     1                               0.0   \n",
      "\n",
      "   ClmCount_Provider_OperatingPhysician  \\\n",
      "0                                   0.0   \n",
      "\n",
      "   ClmCount_Provider_ClmAdmitDiagnosisCode  \\\n",
      "0                                        1   \n",
      "\n",
      "   ClmCount_Provider_ClmProcedureCode_1  ClmCount_Provider_ClmProcedureCode_2  \\\n",
      "0                                   0.0                                   0.0   \n",
      "\n",
      "   ClmCount_Provider_ClmProcedureCode_3  ClmCount_Provider_ClmDiagnosisCode_1  \\\n",
      "0                                   0.0                                     1   \n",
      "\n",
      "   ClmCount_Provider_ClmDiagnosisCode_2  ClmCount_Provider_ClmDiagnosisCode_3  \\\n",
      "0                                     1                                     1   \n",
      "\n",
      "   ClmCount_Provider_ClmDiagnosisCode_4  ClmCount_Provider_ClmDiagnosisCode_5  \\\n",
      "0                                     1                                     1   \n",
      "\n",
      "   ClmCount_Provider_ClmDiagnosisCode_6  ClmCount_Provider_ClmDiagnosisCode_7  \\\n",
      "0                                     1                                     1   \n",
      "\n",
      "   ClmCount_Provider_ClmDiagnosisCode_8  ClmCount_Provider_ClmDiagnosisCode_9  \\\n",
      "0                                     1                                     1   \n",
      "\n",
      "   ClmCount_Provider_ClmDiagnosisCode_10  \\\n",
      "0                                    0.0   \n",
      "\n",
      "   ClmCount_Provider_DiagnosisGroupCode  \\\n",
      "0                                     1   \n",
      "\n",
      "   ClmCount_Provider_BeneID_AttendingPhysician  \\\n",
      "0                                            1   \n",
      "\n",
      "   ClmCount_Provider_BeneID_OtherPhysician  \\\n",
      "0                                      0.0   \n",
      "\n",
      "   ClmCount_Provider_BeneID_OperatingPhysician  \\\n",
      "0                                          0.0   \n",
      "\n",
      "   ClmCount_Provider_BeneID_AttendingPhysician_ClmProcedureCode_1  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_AttendingPhysician_ClmProcedureCode_2  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_AttendingPhysician_ClmProcedureCode_3  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_OperatingPhysician_ClmProcedureCode_1  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_OperatingPhysician_ClmProcedureCode_2  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_OperatingPhysician_ClmProcedureCode_3  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_OtherPhysician_ClmProcedureCode_1  \\\n",
      "0                                                0.0            \n",
      "\n",
      "   ClmCount_Provider_BeneID_OtherPhysician_ClmProcedureCode_2  \\\n",
      "0                                                0.0            \n",
      "\n",
      "   ClmCount_Provider_BeneID_OtherPhysician_ClmProcedureCode_3  \\\n",
      "0                                                0.0            \n",
      "\n",
      "   ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_1  \\\n",
      "0                                                  1                \n",
      "\n",
      "   ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_2  \\\n",
      "0                                                  1                \n",
      "\n",
      "   ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_3  \\\n",
      "0                                                  1                \n",
      "\n",
      "   ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_4  \\\n",
      "0                                                  1                \n",
      "\n",
      "   ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_5  \\\n",
      "0                                                  1                \n",
      "\n",
      "   ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_6  \\\n",
      "0                                                  1                \n",
      "\n",
      "   ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_7  \\\n",
      "0                                                  1                \n",
      "\n",
      "   ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_8  \\\n",
      "0                                                  1                \n",
      "\n",
      "   ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_9  \\\n",
      "0                                                  1                \n",
      "\n",
      "   ClmCount_Provider_BeneID_AttendingPhysician_ClmDiagnosisCode_10  \\\n",
      "0                                                0.0                 \n",
      "\n",
      "   ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_1  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_2  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_3  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_4  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_5  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_6  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_7  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_8  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_9  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_OperatingPhysician_ClmDiagnosisCode_10  \\\n",
      "0                                                0.0                 \n",
      "\n",
      "   ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_1  \\\n",
      "0                                                0.0            \n",
      "\n",
      "   ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_2  \\\n",
      "0                                                0.0            \n",
      "\n",
      "   ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_3  \\\n",
      "0                                                0.0            \n",
      "\n",
      "   ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_4  \\\n",
      "0                                                0.0            \n",
      "\n",
      "   ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_5  \\\n",
      "0                                                0.0            \n",
      "\n",
      "   ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_6  \\\n",
      "0                                                0.0            \n",
      "\n",
      "   ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_7  \\\n",
      "0                                                0.0            \n",
      "\n",
      "   ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_8  \\\n",
      "0                                                0.0            \n",
      "\n",
      "   ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_9  \\\n",
      "0                                                0.0            \n",
      "\n",
      "   ClmCount_Provider_BeneID_OtherPhysician_ClmDiagnosisCode_10  \\\n",
      "0                                                0.0             \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmProcedureCode_1  \\\n",
      "0                                          0.0   \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmProcedureCode_2  \\\n",
      "0                                          0.0   \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmProcedureCode_3  \\\n",
      "0                                          0.0   \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_1  \\\n",
      "0                                            1   \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_2  \\\n",
      "0                                            1   \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_3  \\\n",
      "0                                            1   \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_4  \\\n",
      "0                                            1   \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_5  \\\n",
      "0                                            1   \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_6  \\\n",
      "0                                            1   \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_7  \\\n",
      "0                                            1   \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_8  \\\n",
      "0                                            1   \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_9  \\\n",
      "0                                            1   \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_10  \\\n",
      "0                                           0.0   \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_1_ClmProcedureCode_1  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_1_ClmProcedureCode_2  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_1_ClmProcedureCode_3  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_2_ClmProcedureCode_1  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_2_ClmProcedureCode_2  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_2_ClmProcedureCode_3  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_3_ClmProcedureCode_1  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_3_ClmProcedureCode_2  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_3_ClmProcedureCode_3  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_4_ClmProcedureCode_1  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_4_ClmProcedureCode_2  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_4_ClmProcedureCode_3  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_5_ClmProcedureCode_1  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_5_ClmProcedureCode_2  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_5_ClmProcedureCode_3  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_6_ClmProcedureCode_1  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_6_ClmProcedureCode_2  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_6_ClmProcedureCode_3  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_7_ClmProcedureCode_1  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_7_ClmProcedureCode_2  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_7_ClmProcedureCode_3  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_8_ClmProcedureCode_1  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_8_ClmProcedureCode_2  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_8_ClmProcedureCode_3  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_9_ClmProcedureCode_1  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_9_ClmProcedureCode_2  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_9_ClmProcedureCode_3  \\\n",
      "0                                                0.0                \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_10_ClmProcedureCode_1  \\\n",
      "0                                                0.0                 \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_10_ClmProcedureCode_2  \\\n",
      "0                                                0.0                 \n",
      "\n",
      "   ClmCount_Provider_BeneID_ClmDiagnosisCode_10_ClmProcedureCode_3  \n",
      "0                                                0.0                \n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a51ae6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "# X_train, X_test, y_train, y_test = tts(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0c1d750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "# Standardize the data (train and test)\n",
    "robust_scaler = RobustScaler()\n",
    "robust_scaler.fit(X)\n",
    "X_train_std = robust_scaler.transform(X)\n",
    "# X_test_std = robust_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ca8f4bb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- Admitted?_1\n- Gender_1\n- Is_Alive?_1\n- Race_2\n- Race_3\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[180], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrobust_scaler.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m scaler_file:\n\u001b[0;32m      2\u001b[0m     loaded_scaler \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(scaler_file)\n\u001b[1;32m----> 4\u001b[0m new_data_std \u001b[38;5;241m=\u001b[39m loaded_scaler\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1594\u001b[0m, in \u001b[0;36mRobustScaler.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Center and scale the data.\u001b[39;00m\n\u001b[0;32m   1582\u001b[0m \n\u001b[0;32m   1583\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;124;03m    Transformed array.\u001b[39;00m\n\u001b[0;32m   1592\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1593\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1594\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1595\u001b[0m     X,\n\u001b[0;32m   1596\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1597\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy,\n\u001b[0;32m   1598\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m   1599\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1600\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1601\u001b[0m )\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_scaling:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:580\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    511\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    517\u001b[0m ):\n\u001b[0;32m    518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \n\u001b[0;32m    520\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 580\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    583\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    584\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    585\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    586\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:507\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    503\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n\u001b[1;32m--> 507\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- Admitted?_1\n- Gender_1\n- Is_Alive?_1\n- Race_2\n- Race_3\n- ...\n"
     ]
    }
   ],
   "source": [
    "with open('robust_scaler.pkl', 'rb') as scaler_file:\n",
    "    loaded_scaler = pickle.load(scaler_file)\n",
    "    \n",
    "new_data_std = loaded_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "803756a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('robust_scaler.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(robust_scaler, scaler_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2365fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18377a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.0316228, class_weight=&#x27;balanced&#x27;, intercept_scaling=1.0,\n",
       "                   max_iter=500, penalty=&#x27;l1&#x27;, random_state=49,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.0316228, class_weight=&#x27;balanced&#x27;, intercept_scaling=1.0,\n",
       "                   max_iter=500, penalty=&#x27;l1&#x27;, random_state=49,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.0316228, class_weight='balanced', intercept_scaling=1.0,\n",
       "                   max_iter=500, penalty='l1', random_state=49,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model with all features and hyper-parameterized values\n",
    "log_reg_1 = LogisticRegression(C=0.0316228, penalty='l1',\n",
    "                               fit_intercept=True, solver='liblinear', tol=0.0001, max_iter=500, \n",
    "                               class_weight='balanced',\n",
    "                               verbose=0, \n",
    "                               intercept_scaling=1.0,\n",
    "                               multi_class='auto',\n",
    "                               random_state=49)\n",
    "\n",
    "log_reg_1.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8c4ee4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logistic_regression_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(log_reg_1, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b1b9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "73fcd3f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 293 features, but LogisticRegression is expecting 299 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[190], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, confusion_matrix\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m log_reg_1\u001b[38;5;241m.\u001b[39mpredict(X_train_std)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:432\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    429\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:626\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:415\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    418\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 293 features, but LogisticRegression is expecting 299 features as input."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = log_reg_1.predict(X_train_std)\n",
    "\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "55ef9eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = log_reg_1.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "867b9425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "54203cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s: 907\n",
      "Number of 1s: 175\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming predictions is a NumPy array\n",
    "num_zeros = np.count_nonzero(predictions == 0)\n",
    "num_ones = np.count_nonzero(predictions == 1)\n",
    "\n",
    "print(\"Number of 0s:\", num_zeros)\n",
    "print(\"Number of 1s:\", num_ones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6422bd44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
